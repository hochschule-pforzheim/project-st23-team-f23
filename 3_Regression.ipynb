{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hochschule-pforzheim/project-st23-team-f23/blob/main/3_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dateien ablegen, um sie in Sitzungsspeicher hochzuladen\n",
        "Laufwerk\n",
        "83.52 GB verfügbar\n",
        "Datensatz vorbereiten - Dummies, Skalen\n",
        "Im ersten Schritt wird der Datensatz aus dem ersten Notebook unter dem Namen 'maindf' geladen. Hier muss der Datensatz \"1_Cleansing_Join\" aus dem vorherigen Notebook reingeladen werden."
      ],
      "metadata": {
        "id": "UMZOzgX4BHs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "maindf = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/2_Data_for_Modeltraining.csv\")\n",
        "#maindf = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AI & ML/Projekt/1_Cleansing_Join_final.csv')"
      ],
      "metadata": {
        "id": "X6XYN9neBOjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2453e47-3a20-4805-e257-d36d7b995d5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Durch Ausgabe des Dataframes maindf können wir unseren aktuellen, über Google Drive in colab geladenen Datensatz einsehen.\n"
      ],
      "metadata": {
        "id": "QU5QDRSU_niZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maindf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "jvTXX5P-y6Lo",
        "outputId": "1a678f37-9444-4ec4-b50a-57ace80637f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       is_canceled  lead_time  arrival_date_year  arrival_date_month  \\\n",
              "0                0        342               2015                   7   \n",
              "1                0        737               2015                   7   \n",
              "2                0          7               2015                   7   \n",
              "3                0         13               2015                   7   \n",
              "4                0         14               2015                   7   \n",
              "...            ...        ...                ...                 ...   \n",
              "90909            0         21               2017                   8   \n",
              "90910            0         23               2017                   8   \n",
              "90911            0         34               2017                   8   \n",
              "90912            0        109               2017                   8   \n",
              "90913            0        205               2017                   8   \n",
              "\n",
              "       arrival_date_day_of_month  stay_nights_sum  adults  children  babies  \\\n",
              "0                              1                0       2         0       0   \n",
              "1                              1                0       2         0       0   \n",
              "2                              1                1       1         0       0   \n",
              "3                              1                1       1         0       0   \n",
              "4                              1                2       2         0       0   \n",
              "...                          ...              ...     ...       ...     ...   \n",
              "90909                         30                7       2         0       0   \n",
              "90910                         30                7       2         0       0   \n",
              "90911                         31                7       2         0       0   \n",
              "90912                         31                7       2         0       0   \n",
              "90913                         29                9       2         0       0   \n",
              "\n",
              "       is_repeated_guest  ...  country_CN  country_DEU  country_ESP  \\\n",
              "0                      0  ...           0            0            0   \n",
              "1                      0  ...           0            0            0   \n",
              "2                      0  ...           0            0            0   \n",
              "3                      0  ...           0            0            0   \n",
              "4                      0  ...           0            0            0   \n",
              "...                  ...  ...         ...          ...          ...   \n",
              "90909                  0  ...           0            0            0   \n",
              "90910                  0  ...           0            0            0   \n",
              "90911                  0  ...           0            1            0   \n",
              "90912                  0  ...           0            0            0   \n",
              "90913                  0  ...           0            1            0   \n",
              "\n",
              "       country_GBR  country_IRL  country_ITA  country_NLD  country_PRT  \\\n",
              "0                0            0            0            0            1   \n",
              "1                0            0            0            0            1   \n",
              "2                1            0            0            0            0   \n",
              "3                1            0            0            0            0   \n",
              "4                1            0            0            0            0   \n",
              "...            ...          ...          ...          ...          ...   \n",
              "90909            0            0            0            0            0   \n",
              "90910            0            0            0            0            0   \n",
              "90911            0            0            0            0            0   \n",
              "90912            1            0            0            0            0   \n",
              "90913            0            0            0            0            0   \n",
              "\n",
              "       country_SWE  country_USA  \n",
              "0                0            0  \n",
              "1                0            0  \n",
              "2                0            0  \n",
              "3                0            0  \n",
              "4                0            0  \n",
              "...            ...          ...  \n",
              "90909            0            0  \n",
              "90910            0            0  \n",
              "90911            0            0  \n",
              "90912            0            0  \n",
              "90913            0            0  \n",
              "\n",
              "[90914 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0d2b84b-b4f3-49b5-8735-8c09ec22949a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_canceled</th>\n",
              "      <th>lead_time</th>\n",
              "      <th>arrival_date_year</th>\n",
              "      <th>arrival_date_month</th>\n",
              "      <th>arrival_date_day_of_month</th>\n",
              "      <th>stay_nights_sum</th>\n",
              "      <th>adults</th>\n",
              "      <th>children</th>\n",
              "      <th>babies</th>\n",
              "      <th>is_repeated_guest</th>\n",
              "      <th>...</th>\n",
              "      <th>country_CN</th>\n",
              "      <th>country_DEU</th>\n",
              "      <th>country_ESP</th>\n",
              "      <th>country_GBR</th>\n",
              "      <th>country_IRL</th>\n",
              "      <th>country_ITA</th>\n",
              "      <th>country_NLD</th>\n",
              "      <th>country_PRT</th>\n",
              "      <th>country_SWE</th>\n",
              "      <th>country_USA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>342</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>737</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90909</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>30</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90910</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>30</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90911</th>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90912</th>\n",
              "      <td>0</td>\n",
              "      <td>109</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90913</th>\n",
              "      <td>0</td>\n",
              "      <td>205</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>29</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90914 rows × 43 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0d2b84b-b4f3-49b5-8735-8c09ec22949a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0d2b84b-b4f3-49b5-8735-8c09ec22949a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0d2b84b-b4f3-49b5-8735-8c09ec22949a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYCdd9if3sTX"
      },
      "source": [
        "# **Vorbereitung des Datensatzes auf die Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Wir möchten durch eine Regression die 'average daily rate', also wie teuer ein Zimmer pro Nacht im Schnitt ist, vorhersagen. Dafür müssen wir zuerst aus den Daten die Spalte 'adr' entfernen bzw. diese seperat als y-Variable speichern, da es sich dabei um unsere target-Variable handelt. Durch den Train-Test-Split können wir später das Modell anhand der Trainingsdaten passend auf unsere X- und y-Daten trainieren und über den Abgleich der auf den X-test-Daten vorhergesagten y-Werten zu den tatsächlichen y-test-Daten die Präzision des Modells bestimmen.\n",
        "\n",
        "\n",
        "\n",
        "> Mit dem Befehl `drop(columns='adr')` entfernen wir die adr-Spalte aus den X-Daten. Wir speichern sie dafür mit `y = maindf.adr`.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n_W-VI6W_7nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = maindf.drop(columns='adr')\n",
        "y = maindf.adr"
      ],
      "metadata": {
        "id": "QJAgUDucJvDP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-MA9Xhr4BLl"
      },
      "source": [
        "\n",
        "\n",
        "> Anschließend können wir die Daten mit der Funktion `train_test_split()`, die wir erst importieren müssen, in Trainings- und Testdaten aufteilen. Wir wählen hierfür eine Testgröße von 20% und den Random-State 42.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fnjd34TEbsBV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToLX1uco6FIz"
      },
      "source": [
        "\n",
        "\n",
        "> Mit diesem Split trainieren wir verschiedene Modelle und prüfen über die Accuracy und den f1-Score, welches Modell für unsere Daten die beste Performance bietet. Wir testen\n",
        "\n",
        "*   Lineare Regression\n",
        "*   Support Vector Mechine (LinearSVR)\n",
        "*   Decision Tree\n",
        "*   Gradient Boosting\n",
        "*   XGBoost\n",
        "*   Neuronale Netze\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Außerdem benötigen wir einige Module bzw. Funktionen für alle Modelle, die wir einmal gebündelt zu Beginn importieren:\n",
        "\n"
      ],
      "metadata": {
        "id": "omCVU9iLOjUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "EV77gHKZO0cy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-clOeqGcPU6"
      },
      "source": [
        "\n",
        "> Um unsere Ergebnisse vergleichen zu können, definieren wir nun noch eine `evaluate`-Function, die das Bestimmtheitsmaß (R2), den mittleren absoluten Fehler (MAE), den mittleren quadrierten Fehler (MSE), die Quadratwurzel des mittleren quadratischen Fehlers (RMSE) und den Mittlerer absoluter prozentualer Fehler (MAPE):\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NdLpRhdtcUQ1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "def evaluate(reg, X_test, y_test):\n",
        "  pred = reg.predict(X_test)\n",
        "  print('R2:', r2_score(y_test, pred))\n",
        "  print('MAE:', mean_absolute_error(y_test, pred))\n",
        "  print('MSE:', mean_squared_error(y_test, pred))\n",
        "  print('RMSE:', mean_squared_error(y_test, pred, squared=False))\n",
        "  print('MAPE:', mean_absolute_percentage_error(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Für die Bewertung der Modelle betrachten wir insbesondere das Bestimmtheitsmaß und den mittleren absoluten Fehler.\n",
        "\n"
      ],
      "metadata": {
        "id": "E3tnXoVwC0XI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lineare Regression**"
      ],
      "metadata": {
        "id": "vpPR9yaTC8py"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TZdNa5jh3OC3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linear = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wRCTiHWlWxlI"
      },
      "outputs": [],
      "source": [
        "linear_scaled = make_pipeline(StandardScaler(),\n",
        "                              linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k5r9PR64W29t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "06a48d83-5592-4a1b-a619-cc4431596a20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('linearregression', LinearRegression())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;linearregression&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;linearregression&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "linear_scaled.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kHcDxg9VW4i7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "5f60d2ca-8c5d-407f-d5a4-09948b83737c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-10e5596e9c2d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_lin_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate_lin_reg' is not defined"
          ]
        }
      ],
      "source": [
        "evaluate_lin_reg(linear_scaled, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1gTH2nWMZbl"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import RidgeCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "895nxs9BMoL9"
      },
      "outputs": [],
      "source": [
        "n_alphas = 200\n",
        "alphaValues = np.logspace(-10, -1, n_alphas)\n",
        "\n",
        "linear_ridge = make_pipeline(StandardScaler(),\n",
        "                             RidgeCV(alphas=alphaValues))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxc-o8jTlHQq"
      },
      "outputs": [],
      "source": [
        "linear_ridge.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_6aEsRdlWST"
      },
      "outputs": [],
      "source": [
        "linear_ridge[1].alpha_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvhIEBO3RgOB"
      },
      "outputs": [],
      "source": [
        "evaluate_lin_reg(linear_ridge, X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maindf.adr.mean()"
      ],
      "metadata": {
        "id": "JRbrYO_BcCra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKAPZ1cVagV5"
      },
      "source": [
        "## **SVM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NYvNxFp8zcC"
      },
      "source": [
        "\n",
        "\n",
        "> Als nächstes trainieren und evaluieren wir mithilfe des Support Vector Machine Regressors. Da wir große Datenmengen in das Modell geben, reicht die Standard-Implementierung nicht aus, wir benötigen `LinearSVR` von `sklearn`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GmmzWrgrZytj"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Wir bilden eine Pipeline, in der zuerst die Daten skaliert und dann direkt in das LinearSVR-Modell gegeben werden. Für das Modell verwenden wir wieder den random_state 42 und tol=1e-5. tol bezeichnet dabei den Toleranzwert, unter den der LinearSVR trainiert werden soll. Das Training wird beendet, wenn die Vorhersagen weniger oder gleich dem Toleranzwert von den tatsächlichen Zielwerten abweichen.\n",
        "Ein niedriger Toleranzwert führt zwar zu einer hohen Genauigkeit, verlangsamt dafür aber das Training."
      ],
      "metadata": {
        "id": "yOhel4knYWpF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EsfTnomganCp"
      },
      "outputs": [],
      "source": [
        "lsvr = make_pipeline(StandardScaler(),\n",
        "                     LinearSVR(random_state=42, tol=1e-5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Das Modell kann dann auf die Trainingsdaten trainiert werden.\n",
        "\n"
      ],
      "metadata": {
        "id": "lQR7pKVra4Gj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "29hUT1AMapVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c9d454d7-3388-4493-f11f-d1cf62033f79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('linearsvr', LinearSVR(random_state=42, tol=1e-05))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;linearsvr&#x27;, LinearSVR(random_state=42, tol=1e-05))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;linearsvr&#x27;, LinearSVR(random_state=42, tol=1e-05))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVR</label><div class=\"sk-toggleable__content\"><pre>LinearSVR(random_state=42, tol=1e-05)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "lsvr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> Nach Beenden des Trainings evaluieren wir den LinearSVR anhand der Testdaten.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dvZFvOIha97e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1pmRshGyasyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d282ea-ea30-490a-9f3f-ff68c45c1701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: 0.39195938175867595\n",
            "MAE: 26.760446916694537\n",
            "MSE: 1472.649461870278\n",
            "RMSE: 38.37511513820223\n",
            "MAPE: 5481775411882708.0\n"
          ]
        }
      ],
      "source": [
        "evaluate(lsvr, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJwRQMIEPUyw"
      },
      "source": [
        "\n",
        "\n",
        "> Mit einem Bestimmtheitsmaß von rund 39% ist das Modell nicht sehr stark. Wir versuchen deshalb noch weitere Modelle.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONo9BImmellg"
      },
      "source": [
        "## **Gradient Boosting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V__ZZVBMVloW"
      },
      "source": [
        "\n",
        "\n",
        "> Nach Training und Evaluation des Decision Trees versuchen wir wieder die Ensemble-Implementierung Gradient Boosting, die aus vielen schwächeren Decision Trees ein stärkeres Modell entwickelt. Dafür benötigen wir den `GradientBoostingRegressor` von `sklearn`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o9tdqcRBem1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Wir erstellen die Pipeline aus Scaler und Regressor. Danach trainieren wir das Modell.\n",
        "\n"
      ],
      "metadata": {
        "id": "k5Oyk3GebzbZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "q-kA4LUJeo7o"
      },
      "outputs": [],
      "source": [
        "gb = make_pipeline(StandardScaler(),\n",
        "                   GradientBoostingRegressor(random_state=42))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BUY3lDgeesJf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "24e0f293-afd7-43d9-83d7-c367263c8804"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('gradientboostingregressor',\n",
              "                 GradientBoostingRegressor(random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;gradientboostingregressor&#x27;,\n",
              "                 GradientBoostingRegressor(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;gradientboostingregressor&#x27;,\n",
              "                 GradientBoostingRegressor(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "gb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Die Evaluation zeigt, dass GradientBoosting mit einem Bestimmtheitsmaß von 0,64 deutlich besser performt, als die vorherigen Modelle. Der mittlere absolute Fehler liegt bei 20,86, was bedeutet, dass im Schnitt das Modell die adr um rund 21€ falsch vorhersagt. Wir versuchen, durch Hyperparameter Tuning die Ergebnisse\n",
        " noch zu verbessern.\n",
        "\n"
      ],
      "metadata": {
        "id": "gVJG5qYyb61G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rp6mpapYetWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42fd347-2dc0-45a3-845a-706886f90963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: 0.6419541401266158\n",
            "MAE: 20.865622348836478\n",
            "MSE: 867.1724010683622\n",
            "RMSE: 29.44779110677679\n",
            "MAPE: 3956896952791488.0\n"
          ]
        }
      ],
      "source": [
        "evaluate(gb, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RKBHkNGU2GLM"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GYVzZNPC2HbW"
      },
      "outputs": [],
      "source": [
        "dummy = DummyRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KDawXTNd2KYv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "9ec4e3c2-8f09-45fb-a2e6-ed6bd982607e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DummyRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "dummy.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dXCIBcgu2Osx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50acf9e-e1d9-4896-9b3f-474b4f4c9fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: -0.00044985553542464807\n",
            "MAE: 36.81005815193502\n",
            "MSE: 2423.0485549531177\n",
            "RMSE: 49.22447109876467\n",
            "MAPE: 5951914184838511.0\n"
          ]
        }
      ],
      "source": [
        "evaluate(dummy, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bm3UDb8WcrJ"
      },
      "source": [
        "### **Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6UzfogPWvYu"
      },
      "source": [
        "\n",
        "\n",
        "> Für das Hyperparameter Tuning erstellen wir ein Grid, das die notwendigen Hyperparameter definiert, die im Tuning getestet werden sollen, um daraus die Hyperparameter zu ermitteln, die die besten Ergebnisse erzielen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "qW3YCXi3cYP5"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'gradientboostingregressor__loss': ['ls', 'lad', 'huber', 'quantile'],\n",
        "    'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
        "    'gradientboostingregressor__n_estimators': [100, 500, 1000],\n",
        "    'gradientboostingregressor__max_depth': [3, 5, 7, 9],\n",
        "    'gradientboostingregressor__min_samples_split': [2, 4, 6],\n",
        "    'gradientboostingregressor__min_samples_leaf': [1, 2, 3],\n",
        "    'gradientboostingregressor__subsample': [0.8, 1.0],\n",
        "    'gradientboostingregressor__max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'gradientboostingregressor__random_state': [42],\n",
        "    'standardscaler': [StandardScaler(), None],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZrDKlSnWeZ_"
      },
      "source": [
        "\n",
        "\n",
        "> Wir nutzen nun wieder die RandomizedSearch in Kombination mit cross-validation. Wir übergeben das Modell, das Grid, die Anzahl an Iterationen, die Angabe `n_jobs=-1`, um alle verfügbaren Prozessoren für diese Aufgabe zu nutzen und so eine möglichst niedrige Berechnungszeit zu erreichen, den random_state 42, die Bestimmung der cross-validation auf 5 Folds sowie die Ausgaben (verbose=1) während des Suchprozesses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "houu11J7cNZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cc0732-4976-4ef7-85b9-048822712df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        }
      ],
      "source": [
        "# setting n_jobs=-1 will ensure that sklearn uses all available cpu cores\n",
        "# takes a loooong time (reduce n_iter to make it faster)\n",
        "optimized_gb = RandomizedSearchCV(gb, param_grid, n_iter=100, n_jobs=-1, random_state=42, cv=5, verbose=1)\n",
        "optimized_gb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt-lCUjuX1O-"
      },
      "source": [
        "\n",
        "\n",
        "> Nach dem Tuning geben wir nun die bestmögliche Kombination an Hyperparametern aus, die wir durch Hyperparameter Tuning finden konnten und Evaluieren das optimierte Modell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHnRjUoPckUN"
      },
      "outputs": [],
      "source": [
        "optimized_gb.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4MQq4Hkck-j"
      },
      "outputs": [],
      "source": [
        "evaluate(optimized_gb, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **XGB Regression**"
      ],
      "metadata": {
        "id": "AGczG6aCQdAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Als nächstes testen wir noch die XGB Regression, da diese bei der Classification ein vielversprechendes Modell war. Dafür importieren wir den `XGBRegressor` von `xgboost`, bilden die Pipeline und trainieren das Modell auf die Trainingsdaten. Im Anschluss evaluieren wird wieder anhand der Testdaten.\n"
      ],
      "metadata": {
        "id": "5SCQasZPedkE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRDO86422jBk"
      },
      "outputs": [],
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_tree\n",
        "\n",
        "xgb = make_pipeline(StandardScaler(),\n",
        "                    XGBRegressor())\n",
        "xgb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(xgb, X_test, y_test)"
      ],
      "metadata": {
        "id": "_UiTgx7E_ZJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jly0hnhtgjmJ"
      },
      "outputs": [],
      "source": [
        "#feature_importance = gb.feature_importances_\n",
        "\n",
        "# get indices sorted by importance\n",
        "#sorted_idx = np.argsort(feature_importance)\n",
        "\n",
        "# generate range from 0 to the number of features\n",
        "#pos = np.arange(sorted_idx.shape[0])\n",
        "\n",
        "# 'pos' acts as our value for the 'y' axis\n",
        "#plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "\n",
        "#plt.yticks(pos, np.array(X.columns)[sorted_idx])\n",
        "#plt.title('Feature Importance (MDI)')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "UX962xqxHMi2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ljm2No_38b8"
      },
      "source": [
        "\n",
        "\n",
        "> Um das Modell, das bisher am besten performt nochmals zu verbessern, führen wir auch hier Hyperparameter Tuning durch. Dafür definieren wir wieder das Grid mit den notwendigen Parametern und übergeben es mit dem Modell, cross-validation, Iterations-Anzahl etc. in die RandomizedSearchCV.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08wf9tn838b8"
      },
      "outputs": [],
      "source": [
        "regressor=XGBRegressor()\n",
        "\n",
        "grid = {\n",
        "    'n_estimators': [100, 500, 900, 1100, 1500],\n",
        "    'max_depth':[2, 3, 5, 10, 15],\n",
        "    'learning_rate':[0.05,0.1,0.15,0.20],\n",
        "    'min_child_weight':[1,2,3,4],\n",
        "    'booster':['gbtree','gblinear'],\n",
        "    'base_score':[0.25,0.5,0.75,1]\n",
        "    }\n",
        "\n",
        "random_cv = RandomizedSearchCV(estimator=regressor,\n",
        "            param_distributions=grid,\n",
        "            cv=5, n_iter=50,\n",
        "            scoring = 'neg_mean_absolute_error', n_jobs = -1,\n",
        "            verbose = 1,\n",
        "            return_train_score = True,\n",
        "            random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Wir trainieren das Hyperparameter-Tuning-Modell auf die Trainingsdaten und geben uns die besten estimators aus.\n",
        "\n"
      ],
      "metadata": {
        "id": "V_Cy4eBpgJ7g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw39OIsS38b9"
      },
      "outputs": [],
      "source": [
        "optimized_xgb = random_cv.fit(X_train,y_train)\n",
        "optimized_xgb_est = random_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNCbsm9H38b9"
      },
      "source": [
        "\n",
        "\n",
        "> Auch die Kombination der besten Parameter ist für uns interessant und wir lassen sie auflisten:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNzKLCPQ38b9"
      },
      "outputs": [],
      "source": [
        "optimized_xgb.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Das Ergebnis mit einem Bestimmtheitsmaß von 79% und einem MAE von 12,14€ ist ziemlich gut.\n",
        "\n"
      ],
      "metadata": {
        "id": "2YaFpSIuAwqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMt60ev038b9"
      },
      "outputs": [],
      "source": [
        "evaluate(optimized_xgb, X_train, y_train)\n",
        "evaluate(optimized_xgb, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plotting**"
      ],
      "metadata": {
        "id": "ygXHNAua_tkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "test_score[i] = best_xgb.loss_(y_test, y_pred) hat nicht funktioniert: loss_ nicht in Pipeline => MSE anders berechnen"
      ],
      "metadata": {
        "id": "-pMB8JSKIRYI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-Z1W38qnRA0"
      },
      "outputs": [],
      "source": [
        "# get best xgb model (after hyperparam tuning)\n",
        "best_xgb = optimized_xgb.best_estimator_\n",
        "# staged_predict returns the error after each stage in the model\n",
        "predictions = best_xgb.predict(X_test)\n",
        "# how many estimators were used for the model\n",
        "n_estimators = optimized_xgb.best_params_['xgbregressor__n_estimators']\n",
        "\n",
        "# calculate deviance (error) for all examples in test set\n",
        "test_score = np.zeros((n_estimators,), dtype=np.float64)\n",
        "for i, y_pred in enumerate(predictions):\n",
        "   mse = mean_squared_error(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = xgb.predict(X_train)\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.subplot(1, 1, 1)\n",
        "plt.title('Deviance')\n",
        "plt.plot(np.arange(n_estimators) + 1, train_mse = mean_squared_error(y_train, train_predictions), 'b-',\n",
        "         label='Training Set Deviance')\n",
        "plt.plot(np.arange(n_estimators) + 1, test_score, 'r-',\n",
        "         label='Test Set Deviance')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Boosting Iterations')\n",
        "plt.ylabel('Deviance')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Axq4rYck_6HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXVIpKEMf9Mp"
      },
      "source": [
        "### **Error Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRqV1A7pgGYH"
      },
      "outputs": [],
      "source": [
        "predictions = optimized_xgb.predict(X_test)\n",
        "maindf_with_predictions = pd.concat([X_test, y_test], axis='columns')\n",
        "maindf_with_predictions = pd.concat([maindf_with_predictions, pd.DataFrame(predictions, columns=['Prediction'], index=maindf_with_predictions.index)], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we calculate the difference between the prediction and actual value (MAE):"
      ],
      "metadata": {
        "id": "0WEQIog2U2iu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrNiAwjRgM4g"
      },
      "outputs": [],
      "source": [
        "maindf_with_predictions['pred_diff'] = np.abs(maindf_with_predictions['adr'] - maindf_with_predictions.Prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye0bQ4G9nu86"
      },
      "outputs": [],
      "source": [
        "maindf_with_predictions.pred_diff.plot(kind='hist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FViG4N2xlqMQ"
      },
      "outputs": [],
      "source": [
        "for column in X_test.columns:\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2) # required if we want to plot multiple figures from the same cell\n",
        "  maindf_with_predictions.plot(kind='hist', y=column, title=f'{column} (All)', ax=ax1)\n",
        "  maindf_with_predictions[maindf_with_predictions.pred_diff > 2].plot(kind='hist', y=column, title=f'{column} (Large error)', ax=ax2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **cnn**"
      ],
      "metadata": {
        "id": "jtIyhFLL8jzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "gCZ0ouzG8ifH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "def evaluate(reg, X_test, y_test):\n",
        "  pred = reg.predict(X_test)\n",
        "  print('R2:', r2_score(y_test, pred))\n",
        "  print('MAE:', mean_absolute_error(y_test, pred))\n",
        "  print('MSE:', mean_squared_error(y_test, pred))\n",
        "  print('RMSE:', mean_squared_error(y_test, pred, squared=False))\n",
        "  print('MAPE:', mean_absolute_percentage_error(y_test, pred))"
      ],
      "metadata": {
        "id": "qLzV-QWVBCBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OLZyCXw9Auq"
      },
      "outputs": [],
      "source": [
        "X = maindf_c.drop(columns='adr')\n",
        "y = maindf_c.adr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba8TBQNg9Auu"
      },
      "outputs": [],
      "source": [
        "X_scaled = maindf_scaled.drop(columns='adr')\n",
        "y_scaled = maindf_scaled.is_canceled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akXAVxH99Auv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True)\n",
        "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(1)\n",
        "  ], name=\"MLP_model\")\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "H2CfB4XkDezm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [in €]')\n",
        "  plt.plot(history.epoch, np.array(history.history['mae']),\n",
        "           label='Train')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_mae']),\n",
        "           label = 'Val')\n",
        "  plt.legend()\n",
        "  plt.ylim([min(history.history['val_mae']),max(history.history['val_mae'])])\n",
        "  plt.xlim([0,20])\n",
        "\n",
        "def plot_prediction(test_labels, test_predictions):\n",
        "  plt.figure()\n",
        "  plt.scatter(test_labels, test_predictions)\n",
        "  plt.xlabel('True Values')\n",
        "  plt.ylabel('Predictions')\n",
        "  plt.axis('equal')\n",
        "  plt.xlim([-10, 100])\n",
        "  plt.ylim([-30, 30])\n",
        "  _ = plt.plot([-10, 10],[-10,10])"
      ],
      "metadata": {
        "id": "Ch0VGf93JDMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "history_scaled = model.fit(X_train_scaled, y_train_scaled, epochs=EPOCHS,\n",
        "                    validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "7I1hibr7EJeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, X_test_scaled, y_test_scaled)"
      ],
      "metadata": {
        "id": "_lII4Sh4Bd9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history_scaled)"
      ],
      "metadata": {
        "id": "iHK6PGLoEic5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nicht skalierte Daten"
      ],
      "metadata": {
        "id": "1XfwljofFrjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [in €]')\n",
        "  plt.plot(history.epoch, np.array(history.history['mae']),\n",
        "           label='Train')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_mae']),\n",
        "           label = 'Val')\n",
        "  plt.legend()\n",
        "  plt.ylim([20,max(history.history['val_mae'])])\n",
        "  plt.xlim([0,50])"
      ],
      "metadata": {
        "id": "AAdrF6XuJdcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=EPOCHS,\n",
        "                    validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "lweqBahZHdqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "NMHhKExUHdqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Aus der Grafik können wir erkennen, dass der Mean Absolute Error bei ~24€ liegt."
      ],
      "metadata": {
        "id": "eDAsFLfDLnq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_conv1D_model():\n",
        "\n",
        "  n_timesteps = X_train.shape[1]\n",
        "  n_features  = 1\n",
        "  model = keras.Sequential(name=\"model_conv1D\")\n",
        "  model.add(keras.layers.Input(shape=(n_timesteps,n_features)))\n",
        "  model.add(keras.layers.Conv1D(filters=64, kernel_size=7, activation='relu', name=\"Conv1D_1\"))\n",
        "  model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', name=\"Conv1D_2\"))\n",
        "\n",
        "  model.add(keras.layers.Conv1D(filters=16, kernel_size=2, activation='relu', name=\"Conv1D_3\"))\n",
        "\n",
        "  model.add(keras.layers.MaxPooling1D(pool_size=2, name=\"MaxPooling1D\"))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(32, activation='relu', name=\"Dense_1\"))\n",
        "  model.add(keras.layers.Dense(n_features, name=\"Dense_2\"))\n",
        "\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',optimizer=optimizer,metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model_conv1D = build_conv1D_model()\n",
        "model_conv1D.summary()"
      ],
      "metadata": {
        "id": "DTUUUONSJo7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[loss, mae] = model_conv1D.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Mean Abs Error (test data): {mae}')"
      ],
      "metadata": {
        "id": "4noD78RHIGnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model_conv1D.predict(X_test).flatten()\n",
        "plot_prediction(y_test, test_predictions)"
      ],
      "metadata": {
        "id": "vu6yJYAKJgh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Optimizer: SGD**"
      ],
      "metadata": {
        "id": "ovVvj8VXSDFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(1)\n",
        "  ], name=\"MLP_model\")\n",
        "\n",
        "  optimizer = SGD(lr=0.01, momentum=0.9)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Rx4Z1nEaSJ-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "history_sdg = model.fit(X_train, y_train, epochs=EPOCHS,\n",
        "                    validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "lniwBYgWScui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Optimizer: Adam**"
      ],
      "metadata": {
        "id": "XwgG_8sVS8yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [in €]')\n",
        "  plt.plot(history.epoch, np.array(history.history['mae']),\n",
        "           label='Train')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_mae']),\n",
        "           label = 'Val')\n",
        "  plt.legend()\n",
        "  plt.ylim([min(history.history['val_mae'])-2,max(history.history['val_mae'])+2])\n",
        "  plt.xlim([0,50])"
      ],
      "metadata": {
        "id": "ydKjAQ3ATbQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(1)\n",
        "  ], name=\"MLP_model\")\n",
        "\n",
        "  optimizer = Adam()\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kLV6prmbS8yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "history_adam = model.fit(X_train, y_train, epochs=EPOCHS,\n",
        "                    validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "Vt9-oL64S8yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, X_test, y_test)"
      ],
      "metadata": {
        "id": "a4uPwNMDDspv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history_adam)"
      ],
      "metadata": {
        "id": "oOaQayLGS8yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_conv1D_model():\n",
        "\n",
        "  n_timesteps = X_train.shape[1]\n",
        "  n_features  = 1\n",
        "  model = keras.Sequential(name=\"model_conv1D\")\n",
        "  model.add(keras.layers.Input(shape=(n_timesteps,n_features)))\n",
        "  model.add(keras.layers.Conv1D(filters=64, kernel_size=7, activation='relu', name=\"Conv1D_1\"))\n",
        "  model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', name=\"Conv1D_2\"))\n",
        "\n",
        "  model.add(keras.layers.Conv1D(filters=16, kernel_size=2, activation='relu', name=\"Conv1D_3\"))\n",
        "\n",
        "  model.add(keras.layers.MaxPooling1D(pool_size=2, name=\"MaxPooling1D\"))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(32, activation='relu', name=\"Dense_1\"))\n",
        "  model.add(keras.layers.Dense(n_features, name=\"Dense_2\"))\n",
        "\n",
        "\n",
        "  optimizer = Adam()\n",
        "\n",
        "  model.compile(loss='mse',optimizer=optimizer,metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model_conv1D = build_conv1D_model()\n",
        "model_conv1D.summary()"
      ],
      "metadata": {
        "id": "8hT9irbFU8X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[loss, mae] = model_conv1D.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Mean Abs Error (test data): {mae}')"
      ],
      "metadata": {
        "id": "raXfYjujU8YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model_conv1D.predict(X_test).flatten()\n",
        "plot_prediction(y_test, test_predictions)"
      ],
      "metadata": {
        "id": "shAe78XUU8YF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}